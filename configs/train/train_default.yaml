# Training settings
n_epochs: 1000
batch_size: 128
lr: 0.0002
# shceduler_factor: 0.9
# shceduler_patience: 5
clip_grad: 0.5          # float, null to disable
save_model: True
num_workers: 72
ema_decay: 0           # 'Amount of EMA decay, 0 means off. A reasonable value  is 0.999.'
progress_bar: true
weight_decay: 1e-10
optimizer: adamw # adamw,nadamw,nadam => nadamw for large batches, see http://arxiv.org/abs/2102.06356 for the use of nesterov momentum with large batches
seed: 7